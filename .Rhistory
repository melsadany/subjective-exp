###########################################################################################
#                               Extract Reddit Content                                    #
###########################################################################################
rm(list = ls())
gc()
source("/Dedicated/jmichaelson-wdata/msmuhammad/msmuhammad-source.R")
set.seed(123)
###########################################################################################
library(RedditExtractoR)
devtools::install_github("https://github.com/nathancunn/pushshiftR")
###########################################################################################
###########################################################################################
###########################################################################################
###########################################################################################
# try pushift api
library(pushshiftR)
tmp <- getPushshiftData(postType = "comment",
size = 1000,
after = "1546300800",
subreddit = "depression",
nest_level = 1)
tmp <- getPushshiftData(postType = "comment",
size = 1000,
after = "1546300800",
subreddit = "soccer",
nest_level = 1)
library(jsonlite)
postType = "comment"
size = 1000
after = "1546300800"
subreddit = "soccer"
nest_level = 1
paste("https://api.pushshift.io/reddit/search/",
postType,
"?",
ifelse(is.null(title), "", sprintf("&title=%s", title)),
ifelse(is.null(size), "", sprintf("&size=%s", size)),
ifelse(is.null(q), "", sprintf("&q=%s", q)),
ifelse(is.null(after), "", sprintf("&after=%s", after)),
ifelse(is.null(before), "", sprintf("&before=%s", before)),
ifelse(is.null(subreddit), "", sprintf("&subreddit=%s", subreddit)),
ifelse(is.null(nest_level), "", sprintf("&nest_level=%s", nest_level)),
sep = "")
paste("https://api.pushshift.io/reddit/search/",
postType,
"?", "&size=%s", size, "&after=%s", after, "&subreddit=%s", subreddit, "&nest_level=%s", nest_level)
paste("https://api.pushshift.io/reddit/search/",
postType,
"?", "&size=%s", size, "&after=%s", after, "&subreddit=%s", subreddit, "&nest_level=%s", nest_level, sep = "")
pushift.url <- "https://api.pushshift.io/reddit/search/comment?&size=%s1000&after=%s1546300800&subreddit=%ssoccer&nest_level=%s1"
tmp <- pushift.url %>%
jsonlite::fromJSON() %>%
.$data %>%
jsonlite::flatten(recursive = TRUE) %>%
select(author, body, parent_id, score, created_utc, subreddit) %>%
as_tibble()
get_reddit(subreddit = "Parenting", page_threshold = 2, sort_by = 'new')
###########################################################################################
library(RedditExtractoR)
links <- reddit_urls(
search_terms   = "depression",
page_threshold = 10,
sort_by = 'new'
)
###########################################################################################
library(RedditExtractoR)
###########################################################################################
###########################################################################################
###########################################################################################
###########################################################################################
# try pushift api
library(pushshiftR)
tmp <- getPushshiftData(postType = "comment",
size = 1000,
after = "1546300800",
subreddit = "soccer",
nest_level = 1)
pushift.url <- "https://api.pushshift.io/reddit/search/comment?&size=%s1000&after=%s1546300800&subreddit=%ssoccer&nest_level=%s1"
tmp <- pushift.url %>%
jsonlite::fromJSON() %>%
.$data %>%
jsonlite::flatten(recursive = TRUE) %>%
select(author, body, parent_id, score, created_utc, subreddit) %>%
as_tibble()
pushift.url
tmp <- getPushshiftData(postType = "submession",
size = 1000,
after = "1546300800",
subreddit = "Parenting",
nest_level = 1)
tmp <- getPushshiftData(postType = "submission",
size = 1000,
after = "1546300800",
subreddit = "Parenting",
nest_level = 1)
tmp <- getPushshiftData(postType = "submission",
size = 10,
after = "1546300800",
subreddit = "Parenting",
nest_level = 1)
################################################################################
#                        pre-Reddit looks on project aims                      #
################################################################################
rm(list = ls())
gc()
source("/Dedicated/jmichaelson-wdata/msmuhammad/msmuhammad-source.R")
################################################################################
################################################################################
project.dir <- "/Dedicated/jmichaelson-wdata/msmuhammad/projects/subjective-exp"
setwd(project.dir)
install.packages('zstdr')
devtools::install_github("thekvs/zstdr")
library(zstdr)
tmp <- zstdDecompress("../../data/Reddit/academic-torrents/reddit/submissions/RS_2009-01.zst")
t <- readBin("../../data/Reddit/academic-torrents/reddit/submissions/RS_2009-01.zst", raw(), file.info("../../data/Reddit/academic-torrents/reddit/submissions/RS_2009-01.zst")$size)
t
dec <- zstdDecompress(t)
dec <- zstdCompress(t)
head(t)
t <- readBin("../../data/Reddit/academic-torrents/reddit/submissions/RS_2009-01.zst", file.info("../../data/Reddit/academic-torrents/reddit/submissions/RS_2009-01.zst")$size)
args <- c(1)
################################################################################
reddit.dir <- "/Dedicated/jmichaelson-wdata/msmuhammad/data/Reddit/academic-torrents/reddit/"
dir <- c("comments", "submissions")
files <- list.files(path = paste(reddit.dir, dir[as.numeric(args[1])], sep = "/"))
files
i=44
f <- paste(reddit.dir, dir[as.numeric(args[1])], files[i], sep = "/")
f
################################################################################
reddit.dir <- "/Dedicated/jmichaelson-wdata/msmuhammad/data/Reddit/academic-torrents/reddit"
dir <- c("comments", "submissions")
files <- list.files(path = paste(reddit.dir, dir[as.numeric(args[1])], sep = "/"))
f <- paste(reddit.dir, dir[as.numeric(args[1])], files[i], sep = "/")
f
# d <- system(paste0("zstd -d --ultra --long=31 -c ", f, ".zst"), intern = T) # local command
d <- system(paste0("zstd -d --ultra --long=31 -c ", f), intern = T) # argon command
df <- stream_in(textConnection(d))
library(jsonlite)
df <- stream_in(textConnection(d))
colnames(df)
View(df[1:1000,])
table(df[1:1000,2])
df2 <- df %>%
# filter(!(grepl("deleted", body) | grepl("deleted", author))) # for comments only
filter(!grepl("deleted", author)) %>%
select(-any_of(contains("media"), "preview", "created_utc")) # for submissions only
df2 <- df %>%
# filter(!(grepl("deleted", body) | grepl("deleted", author))) # for comments only
filter(!grepl("deleted", author)) %>%
select(-any_of(c(contains("media"), "preview", "created_utc"))) # for submissions only
View(df2)
df2 <- df %>%
# filter(!(grepl("deleted", body) | grepl("deleted", author))) # for comments only
filter(!grepl("deleted", author)) %>%
distinct(.keep_all = T) %>%
select(-any_of(c(contains("media"), "preview", "created_utc"))) # for submissions only
pdssave(df2, file = paste0(sub("reddit", "derivatives", f, ignore.case = F), ".rds.pxz"))
i=100
f <- paste(reddit.dir, dir[as.numeric(args[1])], files[i], sep = "/")
# d <- system(paste0("zstd -d --ultra --long=31 -c ", f, ".zst"), intern = T) # local command
d <- system(paste0("zstd -d --ultra --long=31 -c ", f), intern = T) # argon command
df <- data.frame(id = 1:length(files), f = files) %>%
mutate(loop = c(rep(1,40),
rep(2,28),
rep(c(3,4,5,6,7,8,9,10,11,12), each = 10),
13:(length(files)-12)))
df <- data.frame(id = 1:length(files), f = files) %>%
mutate(loop = c(rep(1,40),
rep(2,28),
rep(c(3,4,5,6,7,8,9,10,11,12), each = 10),
13:(length(files)-148)))
length(files)
df <- data.frame(id = 1:length(files), f = files) %>%
mutate(loop = c(rep(1,40),
rep(2,28),
rep(c(3,4,5,6,7,8,9,10,11,12), each = 10),
13:(length(files)-148-3)))
df <- data.frame(id = 1:length(files), f = files) %>%
mutate(loop = c(rep(1,40),
rep(2,28),
rep(c(3,4,5,6,7,8,9,10,11,12), each = 10),
13:(length(files)-152)))
length(13:(length(files)-152)))
length(13:(length(files)-152))
length(rep(1,each = 40),
rep(2,each = 28),
rep(c(3,4,5,6,7,8,9,10,11,12), each = 10))
length(rep(1,each = 40),
rep(2,each = 28),
rep(c(3,4,5,6,7,8,9,10,11,12), each = 10)))
length(c(rep(1,each = 40),
rep(2,each = 28),
rep(c(3,4,5,6,7,8,9,10,11,12), each = 10)))
length(c(rep(1,each = 40),
rep(2,each = 28)))
length( c(rep(1,each = 40),
rep(2,each = 28),
rep(c(3,4,5,6,7,8,9,10), each = 10)))
df <- data.frame(id = 1:length(files), f = files) %>%
mutate(loop = c(rep(1,each = 40),
rep(2,each = 28),
rep(c(3,4,5,6,7,8,9,10), each = 10),
11:(length(files)-148)))
df <- data.frame(id = 1:length(files), f = files) %>%
mutate(loop = c(rep(1,each = 40),
rep(2,each = 28),
rep(c(3,4,5,6,7,8,9,10), each = 10),
11:(length(files)-148-10)))
df <- data.frame(id = 1:length(files), f = files) %>%
mutate(loop = c(rep(1,each = 40),
rep(2,each = 28),
rep(c(3,4,5,6,7,8,9,10), each = 10),
11:(length(files)-148+10)))
View(df)
args <- c(1,1)
# args <- c(1,1)
################################################################################
################################################################################
project.dir <- "/Dedicated/jmichaelson-wdata/msmuhammad/projects/subjective-exp"
setwd(project.dir)
################################################################################
reddit.dir <- "/Dedicated/jmichaelson-wdata/msmuhammad/data/Reddit/academic-torrents/reddit"
dir <- c("comments", "submissions")
files2 <- list.files(path = paste(reddit.dir, dir[as.numeric(args[1])], sep = "/"))
df <- data.frame(id = 1:length(files2), f = files2) %>%
mutate(loop = c(rep(1,each = 40),
rep(2,each = 28),
rep(c(3,4,5,6,7,8,9,10), each = 10),
11:(length(files2)-148+10))) %>%
filter(loop = as.numeric(args[2]))
df <- data.frame(id = 1:length(files2), f = files2) %>%
mutate(loop = c(rep(1,each = 40),
rep(2,each = 28),
rep(c(3,4,5,6,7,8,9,10), each = 10),
11:(length(files2)-148+10))) %>%
filter(loop == as.numeric(args[2]))
files <- df$f
df <- data.frame(id = 1:length(files2), f = files2) %>%
mutate(loop = c(rep(1,each = 40),
rep(2,each = 28),
rep(c(3,4,5,6,7,8,9,10), each = 10),
11:(length(files2)-148+10)))
View(df)
args <- c(2,1)
# args <- c(1,1)
# args <- c(2,1)
################################################################################
################################################################################
project.dir <- "/Dedicated/jmichaelson-wdata/msmuhammad/projects/subjective-exp"
setwd(project.dir)
################################################################################
reddit.dir <- "/Dedicated/jmichaelson-wdata/msmuhammad/data/Reddit/academic-torrents/reddit"
dir <- c("comments", "submissions")
files2 <- list.files(path = paste(reddit.dir, dir[as.numeric(args[1])], sep = "/"))
df <- data.frame(id = 1:length(files2), f = files2) %>%
mutate(loop = c(rep(1,each = 40),
rep(2,each = 28),
rep(c(3,4,5,6,7,8,9,10), each = 10),
11:(length(files2)-148+10)))
View(df)
df <- data.frame(id = 1:length(files2), f = files2) %>%
mutate(loop = c(rep(1,each = 40),
rep(2,each = 28),
rep(c(3,4,5,6,7,8,9,10), each = 10),
11:(length(files2)-148+10))) %>%
filter(loop == as.numeric(args[2]))
files <- df$f
remotes::install_github("msgpack/msgpack-r")
remotes::install_github("s-u/zstd")
################################################################################
#                        pre-Reddit looks on project aims                      #
################################################################################
rm(list = ls())
gc()
reticulate::repl_python()
gc()
reticulate::repl_python()
